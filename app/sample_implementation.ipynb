{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepface import DeepFace\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "from qdrant_client import AsyncQdrantClient, models\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "import uuid\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize Qdrant client\n",
    "class QdrantConnection:\n",
    "    def __init__(self) -> None:\n",
    "        self.url = os.getenv('QDRANT_URL', 'http://localhost/')\n",
    "        self.port = os.getenv('QDRANT_PORT', 6333)\n",
    "        self.client = AsyncQdrantClient(url=self.url, port=self.port, timeout=60)\n",
    "\n",
    "    async def create_collection(self, collection_name):\n",
    "        try:\n",
    "            result = await self.client.create_collection(\n",
    "                collection_name=collection_name,\n",
    "                vectors_config=VectorParams(\n",
    "                    size=512, \n",
    "                    distance=Distance.COSINE  # Use COSINE for FaceNet512\n",
    "                ),\n",
    "                optimizers_config=models.OptimizersConfigDiff(\n",
    "                    memmap_threshold=20000  # Use memory-mapped storage for large datasets\n",
    "                ),\n",
    "                hnsw_config=models.HnswConfigDiff(\n",
    "                    m=32,  # Number of connections per node (balances speed & accuracy)\n",
    "                    ef_construct=400,  # Improves recall during indexing\n",
    "                    full_scan_threshold=10000,  # Avoid brute-force scans\n",
    "                    on_disk=True  # Store index on disk for large-scale datasets\n",
    "                ),\n",
    "                quantization_config=models.ScalarQuantization(  # Optional: Enable quantization for memory efficiency\n",
    "                    scalar=models.ScalarQuantizationConfig(\n",
    "                        type=\"int8\", quantile=0.99, always_ram=True\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating collection: {e}\")\n",
    "\n",
    "    async def batch_upload_points_to_collection(self, collection_name, payload):\n",
    "        try:\n",
    "            operation_info = await self.client.upsert(\n",
    "                collection_name=collection_name,\n",
    "                wait=True,\n",
    "                points=models.Batch(\n",
    "                    ids=payload.get('ids'),\n",
    "                    vectors=payload.get('vectors'),\n",
    "                    payloads=payload.get('payload')\n",
    "                )\n",
    "            )\n",
    "            return operation_info\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading points: {e}\")\n",
    "    \n",
    "    async def query_collection(self, collection_name, query_vector: list):\n",
    "        try:\n",
    "            search_result = await self.client.query_points(\n",
    "                collection_name=collection_name,\n",
    "                query=query_vector,\n",
    "                with_payload=True,\n",
    "                limit=3\n",
    "            )\n",
    "            return search_result.points\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying collection: {e}\")\n",
    "\n",
    "qdrant_client = QdrantConnection()\n",
    "\n",
    "# Create collection\n",
    "await qdrant_client.create_collection(\"face-recognition\")\n",
    "\n",
    "# Extract embedding of the given image\n",
    "given_image_path = \"/path/to/your/given/image.jpg\"\n",
    "given_image_result = DeepFace.represent(img_path=given_image_path, model_name=\"Facenet512\", detector_backend=\"mtcnn\")\n",
    "given_image_embedding = given_image_result[0].get('embedding')\n",
    "\n",
    "# Upload given image embedding to Qdrant\n",
    "payload = {\n",
    "    'ids': [str(uuid.uuid4())],\n",
    "    'vectors': [given_image_embedding],\n",
    "    'payload': [{\"file_path\": given_image_path}]\n",
    "}\n",
    "await qdrant_client.batch_upload_points_to_collection('face-recognition', payload)\n",
    "\n",
    "# Initialize video capture\n",
    "video_path = \"/path/to/your/video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Process video frames\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total=frame_count)\n",
    "embeddings = []\n",
    "file_path = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Save the frame as an image file\n",
    "        img_path = \"/tmp/frame.jpg\"\n",
    "        cv2.imwrite(img_path, frame)\n",
    "\n",
    "        # Perform face recognition\n",
    "        result = DeepFace.represent(img_path=img_path, model_name=\"Facenet512\", detector_backend=\"mtcnn\")\n",
    "        for r in result:\n",
    "            if r:\n",
    "                embeddings.append(r.get(\"embedding\"))\n",
    "                file_path.append(img_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "\n",
    "# Upload video frame embeddings to Qdrant\n",
    "payload = {\n",
    "    'ids': [str(uuid.uuid4()) for _ in range(len(embeddings))],\n",
    "    'vectors': embeddings,\n",
    "    'payload': [{\"file_path\": file} for file in file_path]\n",
    "}\n",
    "await qdrant_client.batch_upload_points_to_collection('face-recognition', payload)\n",
    "\n",
    "# Query Qdrant to find frames matching the given image\n",
    "res = await qdrant_client.query_collection('face-recognition', given_image_embedding)\n",
    "print(res)\n",
    "\n",
    "# Display recognized frames\n",
    "for point in res:\n",
    "    frame_path = point.payload['file_path']\n",
    "    frame = cv2.imread(frame_path)\n",
    "    cv2.imshow('Recognized Frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
