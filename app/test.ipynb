{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 05:56:44.962145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738130204.986267 1616149 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738130204.992066 1616149 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 05:56:45.033090: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from deepface import DeepFace\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Facenet512\"\n",
    "detector_backend = \"mtcnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]2025-01-29 05:58:12.201989: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      " 45%|████▌     | 9/20 [00:15<00:20,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face could not be detected in /home/playground/candidate_verification/images/Humans/1 (2011).jpg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:44<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "file_path = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"/home/playground/candidate_verification/images/Humans\"):\n",
    "   for file in tqdm(filenames[:20]):\n",
    "      try:  \n",
    "            img_path = f\"{dirpath}/{file}\"\n",
    "            result =  DeepFace.represent(img_path = img_path, model_name=\"Facenet512\", detector_backend=\"mtcnn\")            \n",
    "            for r in result:\n",
    "                  if r: \n",
    "                     embeddings.append(r.get(\"embedding\"))\n",
    "                     file_path.append(img_path)      \n",
    "      \n",
    "      except Exception as e:\n",
    "         print(e)\n",
    "               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/playground/candidate_verification/images/Humans/1 (4985).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (4707).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (6894).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (5339).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (6143).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (1544).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (6232).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (2672).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (428).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (1336).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (1401).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (664).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (3464).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (29).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (1037).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (6512).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (3518).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (3700).jpg',\n",
       " '/home/playground/candidate_verification/images/Humans/1 (597).jpg']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from qdrant_client import AsyncQdrantClient, models\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "class QdrantConnection:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.url = os.getenv('QDRANT_URL')\n",
    "        self.port = os.getenv('QDRANT_PORT')\n",
    "        self.client = AsyncQdrantClient(url=\"http://localhost/\", port=6333, timeout=60)\n",
    "\n",
    "    async def create_collection(self, collection_name):\n",
    "        try:\n",
    "            result = await self.client.create_collection(\n",
    "                collection_name=collection_name,\n",
    "                vectors_config=VectorParams(\n",
    "                    size=512, \n",
    "                    distance=Distance.COSINE  # Use COSINE for FaceNet512\n",
    "                ),\n",
    "                optimizers_config=models.OptimizersConfigDiff(\n",
    "                    memmap_threshold=20000  # Use memory-mapped storage for large datasets\n",
    "                ),\n",
    "                hnsw_config=models.HnswConfigDiff(\n",
    "                    m=32,  # Number of connections per node (balances speed & accuracy)\n",
    "                    ef_construct=400,  # Improves recall during indexing\n",
    "                    full_scan_threshold=10000,  # Avoid brute-force scans\n",
    "                    on_disk=True  # Store index on disk for large-scale datasets\n",
    "                ),\n",
    "                quantization_config=models.ScalarQuantization(  # Optional: Enable quantization for memory efficiency\n",
    "                    scalar=models.ScalarQuantizationConfig(\n",
    "                        type=\"int8\", quantile=0.99, always_ram=True\n",
    "                    )\n",
    "                )\n",
    "                # payload_schema={  # Define metadata schema for filtering\n",
    "                #     \"person_id\": models.PayloadSchemaType.KEYWORD,\n",
    "                #     \"name\": models.PayloadSchemaType.TEXT,\n",
    "                #     \"age\": models.PayloadSchemaType.INTEGER,\n",
    "                #     \"timestamp\": models.PayloadSchemaType.INTEGER\n",
    "                # }\n",
    "            )\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating collection: {e}\")\n",
    "\n",
    "    async def delete_collection(self, collection_name):\n",
    "        try:\n",
    "            result = await self.client.delete_collection(collection_name=collection_name)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting collection: {e}\")\n",
    "\n",
    "    async def get_collection_info(self, collection_name):\n",
    "        try:\n",
    "            result = await self.client.get_collection(collection_name)\n",
    "            return result    \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting collection info: {e}\")\n",
    "\n",
    "    async def batch_upload_points_to_collection(self, collection_name, payload):\n",
    "        try:\n",
    "            operation_info = await self.client.upsert(\n",
    "                collection_name=collection_name,\n",
    "                wait=True,\n",
    "                points=models.Batch(\n",
    "                    ids=payload.get('ids'),\n",
    "                    vectors=payload.get('vectors'),\n",
    "                    payloads=payload.get('payload')\n",
    "                )\n",
    "            )\n",
    "            return operation_info\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading points: {e}\")\n",
    "    \n",
    "    async def query_collection(self, collection_name, query_vector: list):\n",
    "        try:\n",
    "            search_result = await self.client.query_points(\n",
    "                    collection_name=collection_name,\n",
    "                    query=query_vector,\n",
    "                    with_payload=True,\n",
    "                    limit=3\n",
    "                )\n",
    "            \n",
    "            return search_result.points\n",
    "        \n",
    "        except Exception as e:\n",
    "              print(f\"Error querying collection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await qdrant_client.create_collection(\"face-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await qdrant_client.delete_collection(\"face-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=0 points_count=19 segments_count=8 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=512, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=32, ef_construct=400, full_scan_threshold=10000, max_indexing_threads=0, on_disk=True, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=0.99, always_ram=True)), strict_mode_config=StrictModeConfig(enabled=False, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=None, unindexed_filtering_update=None, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, filter_max_conditions=None, condition_max_size=None)) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "res = await qdrant_client.get_collection_info(\"face-recognition\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp = np.array(embeddings)\n",
    "import uuid\n",
    "payload = {\n",
    "    'ids': [str(uuid.uuid4()) for _ in range(len(embeddings))],\n",
    "    'vectors' : embeddings,\n",
    "    'payload': [{\"file_path\": file} for file in file_path]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "res = await qdrant_client.batch_upload_points_to_collection('face-recognition', payload)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = \"/home/playground/candidate_verification/images/Humans/1 (4985).jpg\"\n",
    "result =  DeepFace.represent(img_path = test_image_path, model_name=\"Facenet512\", detector_backend=\"mtcnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = result[0].get('embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await qdrant_client.query_collection('face-recognition',test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id='05b58719-7eeb-415d-a546-bd24a299fbbf', version=0, score=0.99999994, payload={'file_path': '/home/playground/candidate_verification/images/Humans/1 (4985).jpg'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id='4c89a6ed-8e8e-4632-8c4f-0267c8389003', version=0, score=0.33696622, payload={'file_path': '/home/playground/candidate_verification/images/Humans/1 (664).jpg'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id='56b0b97c-ef45-42c5-9935-09d5f096f48f', version=0, score=0.3196198, payload={'file_path': '/home/playground/candidate_verification/images/Humans/1 (3700).jpg'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
